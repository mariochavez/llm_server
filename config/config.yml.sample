current_model: "vic-13b"
llama_bin: "../llama.cpp/main"
models_path: "./models"

models:
  "orca-3b":
    model: "orca-mini-3b.ggmlv3.q4_0.bin"
    interactive: false
    strip_before: "respuesta: "
    parameters: >
      -n 2048 -c 2048 --top_k 40 --temp 0.1 --repeat_penalty 1.2 -t 6 -ngl 1
    timeout: 90
  "wiz-vic-7b":
    model: "Wizard-Vicuna-7B-Uncensored.ggmlv3.q4_0.bin"
    suffix: "Asistente:"
    reverse_prompt: "Usuario:"
    parameters: >
      -n 2048 -c 2048 --top_k 10000 --temp 0 --repeat_penalty 1.2 -t 4 -ngl 1
    timeout: 90
  "vic-13b-1.3":
    model: "vicuna-13b-v1.3.0.ggmlv3.q4_0.bin"
    suffix: "Asistente:"
    reverse_prompt: "Usuario:"
    parameters: >
      -n 2048 -c 2048 --top_k 10000 --temp 0 --repeat_penalty 1.2 -t 4 -ngl 1
    timeout: 90
